{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7703ad38",
   "metadata": {},
   "source": [
    "# Regenerate all_models.json\n",
    "\n",
    "This script regenerates the `all_models.json` file for each prompt folder by combining all individual model JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec0ff7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded amazon_nova_lite_v1: 4616 entries\n",
      "✓ Loaded amazon_nova_micro_v1: 4616 entries\n",
      "✓ Loaded anthropic_claude_sonnet_4: 4616 entries\n",
      "✓ Loaded cohere_command_r_08_2024: 4616 entries\n",
      "✓ Loaded deepseek_deepseek_chat_v3_1: 4616 entries\n",
      "✓ Loaded google_gemini_2_5_flash: 4616 entries\n",
      "✓ Loaded google_gemma_2_27b_it: 4616 entries\n",
      "✓ Loaded meta_llama_llama_3_1_405b_instruct: 4616 entries\n",
      "✓ Loaded meta_llama_llama_3_3_70b_instruct: 4616 entries\n",
      "✓ Loaded meta_llama_llama_4_maverick: 4616 entries\n",
      "✓ Loaded microsoft_phi_4: 4616 entries\n",
      "✓ Loaded microsoft_wizardlm_2_8x22b: 4616 entries\n",
      "✓ Loaded mistralai_mistral_medium_3: 4616 entries\n",
      "✓ Loaded mistralai_mixtral_8x7b_instruct: 4616 entries\n",
      "✓ Loaded moonshotai_kimi_k2_0905: 4616 entries\n",
      "✓ Loaded openai_gpt_4_1: 4616 entries\n",
      "✓ Loaded openai_o1_mini: 4616 entries\n",
      "✓ Loaded openai_o4_mini_high: 4616 entries\n",
      "✓ Loaded perplexity_sonar: 4616 entries\n",
      "✓ Loaded qwen_qwen2_5_vl_32b_instruct_free: 4616 entries\n",
      "✓ Loaded qwen_qwen_2_5_72b_instruct: 4616 entries\n",
      "✓ Loaded x_ai_grok_3_mini_beta: 4616 entries\n",
      "\n",
      "✓ Successfully created Straico/Prompt 1/all_models.json\n",
      "  Total models: 22\n",
      "  Total entries: 101552\n",
      "\n",
      "✓ Successfully created Straico/Prompt 1/all_models.json\n",
      "  Total models: 22\n",
      "  Total entries: 101552\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def regenerate_all_models_json(prompt_folder_path):\n",
    "    \"\"\"\n",
    "    Regenerates the all_models.json file for a given prompt folder.\n",
    "    \n",
    "    Args:\n",
    "        prompt_folder_path: Path to the prompt folder (e.g., 'Straico/Prompt 1')\n",
    "    \"\"\"\n",
    "    prompt_folder = Path(prompt_folder_path)\n",
    "    \n",
    "    if not prompt_folder.exists():\n",
    "        print(f\"Error: Folder {prompt_folder} does not exist\")\n",
    "        return\n",
    "    \n",
    "    all_models_data = {}\n",
    "    \n",
    "    # Iterate through all subdirectories in the prompt folder\n",
    "    for subdir in sorted(prompt_folder.iterdir()):\n",
    "        # Skip the all_models.json file itself\n",
    "        if subdir.name == \"all_models.json\" or not subdir.is_dir():\n",
    "            continue\n",
    "        \n",
    "        # Look for the JSON file inside the subdirectory\n",
    "        json_file = subdir / f\"{subdir.name}.json\"\n",
    "        \n",
    "        if json_file.exists():\n",
    "            try:\n",
    "                with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                    model_data = json.load(f)\n",
    "                \n",
    "                # Extract the model name from the first entry\n",
    "                if model_data and len(model_data) > 0:\n",
    "                    model_name = model_data[0].get('model', subdir.name)\n",
    "                    all_models_data[model_name] = model_data\n",
    "                    print(f\"✓ Loaded {subdir.name}: {len(model_data)} entries\")\n",
    "                else:\n",
    "                    print(f\"⚠ Warning: {json_file} is empty\")\n",
    "                    \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"✗ Error reading {json_file}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Unexpected error with {json_file}: {e}\")\n",
    "        else:\n",
    "            print(f\"⚠ Warning: {json_file} not found\")\n",
    "    \n",
    "    # Write the combined data to all_models.json\n",
    "    output_file = prompt_folder / \"all_models.json\"\n",
    "    \n",
    "    if all_models_data:\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(all_models_data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        total_entries = sum(len(entries) for entries in all_models_data.values())\n",
    "        print(f\"\\n✓ Successfully created {output_file}\")\n",
    "        print(f\"  Total models: {len(all_models_data)}\")\n",
    "        print(f\"  Total entries: {total_entries}\")\n",
    "    else:\n",
    "        print(\"\\n✗ No data found to write to all_models.json\")\n",
    "\n",
    "\n",
    "# Example usage - change the number to process different prompts\n",
    "prompt_number = 1  # Change this to 2, 3, etc.\n",
    "prompt_folder = f\"Straico/Prompt {prompt_number}\"\n",
    "\n",
    "regenerate_all_models_json(prompt_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ffc7450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing Prompt 1\n",
      "============================================================\n",
      "✓ Loaded amazon_nova_lite_v1: 4616 entries\n",
      "✓ Loaded amazon_nova_micro_v1: 4616 entries\n",
      "✓ Loaded anthropic_claude_sonnet_4: 4616 entries\n",
      "✓ Loaded cohere_command_r_08_2024: 4616 entries\n",
      "✓ Loaded deepseek_deepseek_chat_v3_1: 4616 entries\n",
      "✓ Loaded google_gemini_2_5_flash: 4616 entries\n",
      "✓ Loaded google_gemma_2_27b_it: 4616 entries\n",
      "✓ Loaded meta_llama_llama_3_1_405b_instruct: 4616 entries\n",
      "✓ Loaded meta_llama_llama_3_3_70b_instruct: 4616 entries\n",
      "✓ Loaded meta_llama_llama_4_maverick: 4616 entries\n",
      "✓ Loaded microsoft_phi_4: 4616 entries\n",
      "✓ Loaded microsoft_wizardlm_2_8x22b: 4616 entries\n",
      "✓ Loaded mistralai_mistral_medium_3: 4616 entries\n",
      "✓ Loaded mistralai_mixtral_8x7b_instruct: 4616 entries\n",
      "✓ Loaded moonshotai_kimi_k2_0905: 4616 entries\n",
      "✓ Loaded openai_gpt_4_1: 4616 entries\n",
      "✓ Loaded openai_o1_mini: 4616 entries\n",
      "✓ Loaded openai_o4_mini_high: 4616 entries\n",
      "✓ Loaded perplexity_sonar: 4616 entries\n",
      "✓ Loaded qwen_qwen2_5_vl_32b_instruct_free: 4616 entries\n",
      "✓ Loaded qwen_qwen_2_5_72b_instruct: 4616 entries\n",
      "✓ Loaded x_ai_grok_3_mini_beta: 4616 entries\n",
      "\n",
      "✓ Successfully created Straico/Prompt 1/all_models.json\n",
      "  Total models: 22\n",
      "  Total entries: 101552\n",
      "\n",
      "============================================================\n",
      "Processing Prompt 2\n",
      "============================================================\n",
      "✓ Loaded amazon_nova_lite_v1: 4616 entries\n",
      "✓ Loaded amazon_nova_micro_v1: 4616 entries\n",
      "✓ Loaded anthropic_claude_sonnet_4: 4616 entries\n",
      "✓ Loaded cohere_command_r_08_2024: 4616 entries\n",
      "✓ Loaded deepseek_deepseek_chat_v3_1: 4616 entries\n",
      "✓ Loaded google_gemini_2_5_flash: 4616 entries\n",
      "✓ Loaded google_gemma_2_27b_it: 4616 entries\n",
      "✓ Loaded meta_llama_llama_3_1_405b_instruct: 4616 entries\n",
      "✓ Loaded meta_llama_llama_3_3_70b_instruct: 4616 entries\n",
      "✓ Loaded meta_llama_llama_4_maverick: 4616 entries\n",
      "✓ Loaded microsoft_phi_4: 4616 entries\n",
      "✓ Loaded microsoft_wizardlm_2_8x22b: 4616 entries\n",
      "✓ Loaded mistralai_mistral_medium_3: 4616 entries\n",
      "✓ Loaded mistralai_mixtral_8x7b_instruct: 4616 entries\n",
      "✓ Loaded moonshotai_kimi_k2_0905: 4616 entries\n",
      "✓ Loaded openai_gpt_4_1: 4616 entries\n",
      "✓ Loaded openai_o1_mini: 4616 entries\n",
      "✓ Loaded openai_o4_mini_high: 4616 entries\n",
      "✓ Loaded perplexity_sonar: 4616 entries\n",
      "✓ Loaded qwen_qwen2_5_vl_32b_instruct_free: 4616 entries\n",
      "✓ Loaded qwen_qwen_2_5_72b_instruct: 4616 entries\n",
      "✓ Loaded x_ai_grok_3_mini_beta: 4616 entries\n",
      "\n",
      "✓ Successfully created Straico/Prompt 1/all_models.json\n",
      "  Total models: 22\n",
      "  Total entries: 101552\n",
      "\n",
      "============================================================\n",
      "Processing Prompt 2\n",
      "============================================================\n",
      "✓ Loaded amazon_nova_lite_v1: 4616 entries\n",
      "✓ Loaded amazon_nova_micro_v1: 4616 entries\n",
      "✓ Loaded anthropic_claude_sonnet_4: 4616 entries\n",
      "✓ Loaded cohere_command_r_08_2024: 4616 entries\n",
      "✓ Loaded deepseek_deepseek_chat_v3_1: 4616 entries\n",
      "✓ Loaded google_gemini_2_5_flash: 4616 entries\n",
      "✓ Loaded google_gemma_2_27b_it: 4616 entries\n",
      "✓ Loaded meta_llama_llama_3_1_405b_instruct: 4616 entries\n",
      "✓ Loaded meta_llama_llama_3_3_70b_instruct: 4616 entries\n",
      "✓ Loaded meta_llama_llama_4_maverick: 4616 entries\n",
      "✓ Loaded microsoft_phi_4: 4616 entries\n",
      "✓ Loaded microsoft_wizardlm_2_8x22b: 4616 entries\n",
      "✓ Loaded mistralai_mistral_medium_3: 4616 entries\n",
      "✓ Loaded mistralai_mixtral_8x7b_instruct: 4616 entries\n",
      "✓ Loaded moonshotai_kimi_k2_0905: 4616 entries\n",
      "✓ Loaded openai_gpt_4_1: 4616 entries\n",
      "✓ Loaded openai_o1_mini: 4616 entries\n",
      "✓ Loaded openai_o4_mini_high: 4616 entries\n",
      "✓ Loaded perplexity_sonar: 4616 entries\n",
      "✓ Loaded qwen_qwen2_5_vl_32b_instruct_free: 4616 entries\n",
      "✓ Loaded qwen_qwen_2_5_72b_instruct: 4616 entries\n",
      "✓ Loaded x_ai_grok_3_mini_beta: 4616 entries\n",
      "\n",
      "✓ Successfully created Straico/Prompt 2/all_models.json\n",
      "  Total models: 22\n",
      "  Total entries: 101552\n",
      "\n",
      "============================================================\n",
      "Processing Prompt 3\n",
      "============================================================\n",
      "✓ Loaded amazon_nova_lite_v1: 4616 entries\n",
      "✓ Loaded amazon_nova_micro_v1: 4616 entries\n",
      "✓ Loaded anthropic_claude_sonnet_4: 4616 entries\n",
      "✓ Loaded cohere_command_r_08_2024: 4616 entries\n",
      "✓ Loaded deepseek_deepseek_chat_v3_1: 4616 entries\n",
      "✓ Loaded google_gemini_2_5_flash: 4616 entries\n",
      "✓ Loaded google_gemma_2_27b_it: 4616 entries\n",
      "✓ Loaded meta_llama_llama_3_1_405b_instruct: 4616 entries\n",
      "✓ Loaded meta_llama_llama_3_3_70b_instruct: 4616 entries\n",
      "✓ Loaded meta_llama_llama_4_maverick: 4616 entries\n",
      "✓ Loaded microsoft_phi_4: 4616 entries\n",
      "✓ Loaded microsoft_wizardlm_2_8x22b: 4616 entries\n",
      "✓ Loaded mistralai_mistral_medium_3: 4616 entries\n",
      "✓ Loaded mistralai_mixtral_8x7b_instruct: 4616 entries\n",
      "✓ Loaded moonshotai_kimi_k2_0905: 4616 entries\n",
      "✓ Loaded openai_gpt_4_1: 4616 entries\n",
      "✓ Loaded openai_o1_mini: 4616 entries\n",
      "✓ Loaded openai_o4_mini_high: 4616 entries\n",
      "✓ Loaded perplexity_sonar: 4616 entries\n",
      "✓ Loaded qwen_qwen2_5_vl_32b_instruct_free: 4616 entries\n",
      "✓ Loaded qwen_qwen_2_5_72b_instruct: 4616 entries\n",
      "✓ Loaded x_ai_grok_3_mini_beta: 4616 entries\n",
      "\n",
      "✓ Successfully created Straico/Prompt 2/all_models.json\n",
      "  Total models: 22\n",
      "  Total entries: 101552\n",
      "\n",
      "============================================================\n",
      "Processing Prompt 3\n",
      "============================================================\n",
      "✓ Loaded amazon_nova_lite_v1: 4616 entries\n",
      "✓ Loaded amazon_nova_micro_v1: 4616 entries\n",
      "✓ Loaded anthropic_claude_sonnet_4: 4616 entries\n",
      "✓ Loaded cohere_command_r_08_2024: 4616 entries\n",
      "✓ Loaded deepseek_deepseek_chat_v3_1: 4616 entries\n",
      "✓ Loaded google_gemini_2_5_flash: 4616 entries\n",
      "✓ Loaded google_gemma_2_27b_it: 4616 entries\n",
      "✓ Loaded meta_llama_llama_3_1_405b_instruct: 4616 entries\n",
      "✓ Loaded meta_llama_llama_3_3_70b_instruct: 4616 entries\n",
      "✓ Loaded meta_llama_llama_4_maverick: 4616 entries\n",
      "✓ Loaded microsoft_phi_4: 4616 entries\n",
      "✓ Loaded microsoft_wizardlm_2_8x22b: 4616 entries\n",
      "✓ Loaded mistralai_mistral_medium_3: 4616 entries\n",
      "✓ Loaded mistralai_mixtral_8x7b_instruct: 4616 entries\n",
      "✓ Loaded moonshotai_kimi_k2_0905: 4616 entries\n",
      "✓ Loaded openai_gpt_4_1: 4616 entries\n",
      "✓ Loaded openai_o1_mini: 4616 entries\n",
      "✓ Loaded openai_o4_mini_high: 4616 entries\n",
      "✓ Loaded perplexity_sonar: 4616 entries\n",
      "✓ Loaded qwen_qwen2_5_vl_32b_instruct_free: 4616 entries\n",
      "✓ Loaded qwen_qwen_2_5_72b_instruct: 4616 entries\n",
      "✓ Loaded x_ai_grok_3_mini_beta: 4616 entries\n",
      "\n",
      "✓ Successfully created Straico/Prompt 3/all_models.json\n",
      "  Total models: 22\n",
      "  Total entries: 101552\n",
      "\n",
      "✓ Successfully created Straico/Prompt 3/all_models.json\n",
      "  Total models: 22\n",
      "  Total entries: 101552\n"
     ]
    }
   ],
   "source": [
    "# To process all prompt folders automatically:\n",
    "straico_base = Path(\"Straico\")\n",
    "\n",
    "if straico_base.exists():\n",
    "    for prompt_folder in sorted(straico_base.iterdir()):\n",
    "        if prompt_folder.is_dir() and prompt_folder.name.startswith(\"Prompt\"):\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Processing {prompt_folder.name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            regenerate_all_models_json(prompt_folder)\n",
    "else:\n",
    "    print(\"Straico folder not found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

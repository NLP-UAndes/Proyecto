{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6890dc73",
   "metadata": {},
   "source": [
    "# Cost Analysis: API Usage for Modismos Dataset\n",
    "\n",
    "This notebook calculates the total cost in coins for processing the complete modismos dataset using all available models across three different prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac568c9",
   "metadata": {},
   "source": [
    "## Configuration and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7a86c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique modismos: 20\n",
      "Total models available: 67\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "MODELS_FILE = 'Straico/text_only_models.json'\n",
    "DATASET_FILE = 'modismos_Dataset_Final.csv'\n",
    "\n",
    "# Load models data\n",
    "with open(MODELS_FILE, 'r', encoding='utf-8') as f:\n",
    "    models_data = json.load(f)\n",
    "\n",
    "# Load dataset and count unique modismos\n",
    "modismos_unicos = set()\n",
    "with open(DATASET_FILE, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f, delimiter=';')\n",
    "    for row in reader:\n",
    "        modismo = row.get('modismo', '').strip()\n",
    "        if modismo:\n",
    "            modismos_unicos.add(modismo.casefold())\n",
    "\n",
    "n_modismos_unicos = len(modismos_unicos)\n",
    "n_modismos_unicos = 20\n",
    "n_models = len(models_data['text_models'])\n",
    "\n",
    "print(f\"Total unique modismos: {n_modismos_unicos:,}\")\n",
    "print(f\"Total models available: {n_models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4207844",
   "metadata": {},
   "source": [
    "## Prompt Specifications\n",
    "\n",
    "Definition of input and output word counts for each prompt type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ac2ffdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt Specifications:\n",
      "  Prompt                              Description  Input (words)  Output (words)  Total words API Calls\n",
      "Prompt 1                     Modismo → Definición            138              22          160        20\n",
      "Prompt 2             Modismo → Es Modismo (Sí/No)            113              21          134        20\n",
      "Prompt 3 Modismo + Ejemplo → Literal + Definición            227              52          279        20\n"
     ]
    }
   ],
   "source": [
    "# Prompt specifications (words)\n",
    "PROMPTS = {\n",
    "    'Prompt 1': {\n",
    "        'description': 'Modismo → Definición',\n",
    "        'input_words': 138,\n",
    "        'output_words': 22,\n",
    "        'n_calls': n_modismos_unicos  # One call per unique modismo\n",
    "    },\n",
    "    'Prompt 2': {\n",
    "        'description': 'Modismo → Es Modismo (Sí/No)',\n",
    "        'input_words': 113,\n",
    "        'output_words': 21,\n",
    "        'n_calls': n_modismos_unicos  # One call per unique modismo\n",
    "    },\n",
    "    'Prompt 3': {\n",
    "        'description': 'Modismo + Ejemplo → Literal + Definición',\n",
    "        'input_words': 227,\n",
    "        'output_words': 52,\n",
    "        'n_calls': n_modismos_unicos  # One call per unique modismo\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display prompt specifications\n",
    "prompt_df = pd.DataFrame([\n",
    "    {\n",
    "        'Prompt': name,\n",
    "        'Description': info['description'],\n",
    "        'Input (words)': info['input_words'],\n",
    "        'Output (words)': info['output_words'],\n",
    "        'Total words': info['input_words'] + info['output_words'],\n",
    "        'API Calls': f\"{info['n_calls']:,}\"\n",
    "    }\n",
    "    for name, info in PROMPTS.items()\n",
    "])\n",
    "\n",
    "print(\"\\nPrompt Specifications:\")\n",
    "print(prompt_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de9affd",
   "metadata": {},
   "source": [
    "## Cost Calculation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a6173c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(model, input_words, output_words):\n",
    "    \"\"\"\n",
    "    Calculate the cost in coins for a single API call.\n",
    "    \n",
    "    Args:\n",
    "        model: Model pricing information dictionary\n",
    "        input_words: Number of input words\n",
    "        output_words: Number of output words\n",
    "    \n",
    "    Returns:\n",
    "        Total cost in coins for the call\n",
    "    \"\"\"\n",
    "    pricing = model['pricing']\n",
    "    coins_per_100_words = pricing['coins']\n",
    "    \n",
    "    total_words = input_words + output_words\n",
    "    cost = (total_words / 100.0) * coins_per_100_words\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c1e5b",
   "metadata": {},
   "source": [
    "## Total Cost Calculation per Model and Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f86c7707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Analysis Summary:\n",
      "================================================================================\n",
      "                                                Model                                   Model ID  Coins/100 words  Prompt 1 (total)  Prompt 2 (total)  Prompt 3 (total)  Total Cost\n",
      "                               Amazon: Nova Micro 1.0                       amazon/nova-micro-v1             0.10              3.20              2.68              5.58       11.46\n",
      "                                     Microsoft: Phi 4                            microsoft/phi-4             0.10              3.20              2.68              5.58       11.46\n",
      "                                Amazon: Nova Lite 1.0                        amazon/nova-lite-v1             0.20              6.40              5.36             11.16       22.92\n",
      "                          Cohere: Command R (08-2024)                   cohere/command-r-08-2024             0.20              6.40              5.36             11.16       22.92\n",
      "                           Google: Gemini Flash 2.08B                google/gemini-2.0-flash-001             0.20              6.40              5.36             11.16       22.92\n",
      "                             Mistral: Codestral Mamba                  mistralai/codestral-mamba             0.20              6.40              5.36             11.16       22.92\n",
      "                                Qwen2-VL 72B Instruct                qwen/qwen-2-vl-72b-instruct             0.20              6.40              5.36             11.16       22.92\n",
      "                                 Qwen2.5 72B Instruct                 qwen/qwen-2.5-72b-instruct             0.20              6.40              5.36             11.16       22.92\n",
      "                                  Google: Gemma 2 27B                      google/gemma-2-27b-it             0.40             12.80             10.72             22.32       45.84\n",
      "                                  Qwen 2 72B Instruct                   qwen/qwen-2-72b-instruct             0.50             16.00             13.40             27.90       57.30\n",
      "                                   OpenAI: GPT-5 Nano                          openai/gpt-5-nano             0.50             16.00             13.40             27.90       57.30\n",
      "              NVIDIA: Llama 3.3 Nemotron Super 49B v1     nvidia/llama-3.3-nemotron-super-49b-v1             0.50             16.00             13.40             27.90       57.30\n",
      "                                 OpenAI: GPT-4.1 Nano                        openai/gpt-4.1-nano             0.50             16.00             13.40             27.90       57.30\n",
      "                                  MiniMax: MiniMax M2                    minimax/minimax-m2:free             0.50             16.00             13.40             27.90       57.30\n",
      "                         Meta: Llama 3.3 70B Instruct          meta-llama/llama-3.3-70b-instruct             0.50             16.00             13.40             27.90       57.30\n",
      "                        Google: Gemini 2.5 Flash Lite               google/gemini-2.5-flash-lite             0.50             16.00             13.40             27.90       57.30\n",
      "NVIDIA: Llama 3.3 Nemotron Super 49B V1.5 (Reasoning)   nvidia/llama-3.3-nemotron-super-49b-v1.5             0.50             16.00             13.40             27.90       57.30\n",
      "                      Qwen: Qwen3 235B A22B Reasoning                       qwen/qwen3-235b-a22b             0.60             19.20             16.08             33.48       68.76\n",
      "                                     WizardLM-2 8x22B                 microsoft/wizardlm-2-8x22b             0.60             19.20             16.08             33.48       68.76\n",
      "                         Meta: Llama 3.1 70B Instruct          meta-llama/llama-3.1-70b-instruct             0.70             22.40             18.76             39.06       80.22\n",
      "                               Meta: Llama 4 Maverick                meta-llama/llama-4-maverick             0.70             22.40             18.76             39.06       80.22\n",
      "             NVIDIA: Llama 3.1 Nemotron Ultra 253B v1    nvidia/llama-3.1-nemotron-ultra-253b-v1             0.70             22.40             18.76             39.06       80.22\n",
      "                        Qwen: Qwen2.5 VL 32B Instruct          qwen/qwen2.5-vl-32b-instruct:free             0.70             22.40             18.76             39.06       80.22\n",
      "                                 OpenAI: GPT-4.1 Mini                        openai/gpt-4.1-mini             1.00             32.00             26.80             55.80      114.60\n",
      "                                     xAI: Grok 4 Fast                           x-ai/grok-4-fast             1.00             32.00             26.80             55.80      114.60\n",
      "                                        Z.AI: GLM 4.6                               z-ai/glm-4.6             1.00             32.00             26.80             55.80      114.60\n",
      "                             Z.AI: GLM 4.5V Reasoning                              z-ai/glm-4.5v             1.00             32.00             26.80             55.80      114.60\n",
      "                                   OpenAI: GPT-5 Mini                          openai/gpt-5-mini             1.00             32.00             26.80             55.80      114.60\n",
      "                             MoonshotAI: Kimi K2 0711                    moonshotai/kimi-k2:free             1.00             32.00             26.80             55.80      114.60\n",
      "                                    Perplexity: Sonar                           perplexity/sonar             1.00             32.00             26.80             55.80      114.60\n",
      "                            Mistral: Mistral Medium 3                 mistralai/mistral-medium-3             1.00             32.00             26.80             55.80      114.60\n",
      "                   Meta: Llama 3 70B Instruct (nitro)      meta-llama/llama-3-70b-instruct:nitro             1.00             32.00             26.80             55.80      114.60\n",
      "                           Gryphe: MythoMax L2 13B 8k                     gryphe/mythomax-l2-13b             1.00             32.00             26.80             55.80      114.60\n",
      "                                Mistral: Mixtral 8x7B            mistralai/mixtral-8x7b-instruct             1.00             32.00             26.80             55.80      114.60\n",
      "                             Google: Gemini 2.5 Flash                    google/gemini-2.5-flash             1.00             32.00             26.80             55.80      114.60\n",
      "                             Dolphin 2.6 Mixtral 8x7B cognitivecomputations/dolphin-mixtral-8x7b             1.00             32.00             26.80             55.80      114.60\n",
      "                           DeepSeek: DeepSeek V3 0324             deepseek/deepseek-chat-v3-0324             1.00             32.00             26.80             55.80      114.60\n",
      "                                          DeepSeek V3                     deepseek/deepseek-chat             1.10             35.20             29.48             61.38      126.06\n",
      "                      xAI: Grok 3 Mini Beta Reasoning                      x-ai/grok-3-mini-beta             1.30             41.60             34.84             72.54      148.98\n",
      "                             OpenAI: o3 Mini (Medium)                             openai/o3-mini             1.50             48.00             40.20             83.70      171.90\n",
      "                                      OpenAI: o4 Mini                             openai/o4-mini             1.50             48.00             40.20             83.70      171.90\n",
      "                        Meta: Llama 3.1 405B Instruct         meta-llama/llama-3.1-405b-instruct             1.60             51.20             42.88             89.28      183.36\n",
      "                              DeepSeek: DeepSeek V3.1                deepseek/deepseek-chat-v3.1             2.00             64.00             53.60            111.60      229.20\n",
      "                             MoonshotAI: Kimi K2 0905                    moonshotai/kimi-k2-0905             2.00             64.00             53.60            111.60      229.20\n",
      "                          Perplexity: Sonar Reasoning                 perplexity/sonar-reasoning             2.20             70.40             58.96            122.76      252.12\n",
      "                                 OpenAI: o4 Mini High                        openai/o4-mini-high             2.40             76.80             64.32            133.92      275.04\n",
      "                               OpenAI: o3 Mini (High)                        openai/o3-mini-high             3.00             96.00             80.40            167.40      343.80\n",
      "                                    Qwen: Qwen3 Coder                           qwen/qwen3-coder             3.00             96.00             80.40            167.40      343.80\n",
      "                                      OpenAI: GPT-4.1                             openai/gpt-4.1             3.00             96.00             80.40            167.40      343.80\n",
      "                                     xAI: Grok 2 1212                           x-ai/grok-2-1212             3.20            102.40             85.76            178.56      366.72\n",
      "                         Cohere: Command R+ (08-2024)              cohere/command-r-plus-08-2024             3.40            108.80             91.12            189.72      389.64\n",
      "                               Google: Gemini Pro 1.5                      google/gemini-pro-1.5             3.70            118.40             99.16            206.46      424.02\n",
      "                                      OpenAI: o1 mini                             openai/o1-mini             4.00            128.00            107.20            223.20      458.40\n",
      "                                         Goliath 120B                     alpindale/goliath-120b             5.00            160.00            134.00            279.00      573.00\n",
      "                                   OpenAI: GPT-5 Chat                          openai/gpt-5-chat             5.00            160.00            134.00            279.00      573.00\n",
      "              DeepSeek: DeepSeek R1 Reasoning (nitro)                 deepseek/deepseek-r1:nitro             5.16            165.12            138.29            287.93      591.34\n",
      "                      DeepSeek: DeepSeek R1 Reasoning                       deepseek/deepseek-r1             5.16            165.12            138.29            287.93      591.34\n",
      "                           Anthropic: Claude Sonnet 4                  anthropic/claude-sonnet-4             6.00            192.00            160.80            334.80      687.60\n",
      "                                        OpenAI: GPT-5                               openai/gpt-5             8.00            256.00            214.40            446.40      916.80\n",
      "                                     xAI: Grok 3 Beta                           x-ai/grok-3-beta             8.00            256.00            214.40            446.40      916.80\n",
      "                         Anthropic: Claude Sonnet 4.5                anthropic/claude-sonnet-4.5            10.00            320.00            268.00            558.00    1,146.00\n",
      "                                xAI: Grok 4 Reasoning                                x-ai/grok-4            10.00            320.00            268.00            558.00    1,146.00\n",
      "           Google: Gemini Pro 2.5 Reasoning (Preview)              google/gemini-2.5-pro-preview            16.60            531.20            444.88            926.28    1,902.36\n",
      "                                           OpenAI: o1                                  openai/o1            20.00            640.00            536.00          1,116.00    2,292.00\n",
      "                                           OpenAI: o3                              o3-2025-04-16            20.00            640.00            536.00          1,116.00    2,292.00\n",
      "                           Anthropic: Claude Opus 4.1                    anthropic/claude-opus-4            30.00            960.00            804.00          1,674.00    3,438.00\n",
      "                            OpenAI: o1 High Reasoning                              openai/o1-pro            35.00          1,120.00            938.00          1,953.00    4,011.00\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Calculate costs for all models and prompts\n",
    "cost_analysis = []\n",
    "\n",
    "for model in models_data['text_models']:\n",
    "    model_name = model['name']\n",
    "    model_id = model['model']\n",
    "    pricing_info = model['pricing']\n",
    "    \n",
    "    model_costs = {\n",
    "        'Model': model_name,\n",
    "        'Model ID': model_id,\n",
    "        'Coins/100 words': pricing_info['coins']\n",
    "    }\n",
    "    \n",
    "    total_model_cost = 0\n",
    "    \n",
    "    for prompt_name, prompt_info in PROMPTS.items():\n",
    "        cost_per_call = calculate_cost(\n",
    "            model,\n",
    "            prompt_info['input_words'],\n",
    "            prompt_info['output_words']\n",
    "        )\n",
    "        \n",
    "        total_prompt_cost = cost_per_call * prompt_info['n_calls']\n",
    "        model_costs[f\"{prompt_name} (total)\"] = total_prompt_cost\n",
    "        total_model_cost += total_prompt_cost\n",
    "    \n",
    "    model_costs['Total Cost'] = total_model_cost\n",
    "    cost_analysis.append(model_costs)\n",
    "\n",
    "# Create DataFrame\n",
    "cost_df = pd.DataFrame(cost_analysis)\n",
    "\n",
    "# Sort by total cost\n",
    "cost_df = cost_df.sort_values('Total Cost', ascending=True)\n",
    "\n",
    "print(\"Cost Analysis Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(cost_df.to_string(index=False, float_format=\"{:,.2f}\".format))\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ba6b813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grand Total Cost:\n",
      "28,262.65 coins\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the total cost across all models and prompts\n",
    "total_cost = cost_df['Total Cost'].sum()\n",
    "print(\"\\nGrand Total Cost:\")\n",
    "print(f\"{total_cost:,.2f} coins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41add9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Models contributing to Total Cost > 1,000,000 coins:\n",
      "['Amazon: Nova Micro 1.0', 'Microsoft: Phi 4', 'Amazon: Nova Lite 1.0', 'Cohere: Command R (08-2024)', 'Google: Gemini Flash 2.08B', 'Mistral: Codestral Mamba', 'Qwen2-VL 72B Instruct', 'Qwen2.5 72B Instruct', 'Google: Gemma 2 27B', 'Qwen 2 72B Instruct', 'OpenAI: GPT-5 Nano', 'NVIDIA: Llama 3.3 Nemotron Super 49B v1', 'OpenAI: GPT-4.1 Nano', 'MiniMax: MiniMax M2', 'Meta: Llama 3.3 70B Instruct', 'Google: Gemini 2.5 Flash Lite', 'NVIDIA: Llama 3.3 Nemotron Super 49B V1.5 (Reasoning)', 'Qwen: Qwen3 235B A22B Reasoning', 'WizardLM-2 8x22B', 'Meta: Llama 3.1 70B Instruct', 'Meta: Llama 4 Maverick']\n",
      "\n",
      "Cumulative Total: 962.64 coins\n"
     ]
    }
   ],
   "source": [
    "# Incrementally sum model costs until the total exceeds 1 million coins\n",
    "incremental_sum = 0\n",
    "models_until_threshold = []\n",
    "\n",
    "for _, row in cost_df.iterrows():\n",
    "    incremental_sum += row['Total Cost']\n",
    "    models_until_threshold.append(row['Model'])\n",
    "    if incremental_sum > 1_000:\n",
    "        break\n",
    "\n",
    "print(\"\\nModels contributing to Total Cost > 1,000,000 coins:\")\n",
    "print(models_until_threshold)\n",
    "print(f\"\\nCumulative Total: {incremental_sum:,.2f} coins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0f1c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

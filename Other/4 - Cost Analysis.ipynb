{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6890dc73",
   "metadata": {},
   "source": [
    "# Cost Analysis: API Usage for Modismos Dataset\n",
    "\n",
    "This notebook calculates the total cost in coins for processing the complete modismos dataset using all available models across three different prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac568c9",
   "metadata": {},
   "source": [
    "## Configuration and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a86c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique modismos: 6,531\n",
      "Total models available: 67\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "MODELS_FILE = 'Straico/text_only_models.json'\n",
    "DATASET_FILE = 'modismos_Dataset_Final.csv'\n",
    "\n",
    "# Load models data\n",
    "with open(MODELS_FILE, 'r', encoding='utf-8') as f:\n",
    "    models_data = json.load(f)\n",
    "\n",
    "# Load dataset and count unique modismos\n",
    "modismos_unicos = set()\n",
    "with open(DATASET_FILE, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f, delimiter=';')\n",
    "    for row in reader:\n",
    "        modismo = row.get('modismo', '').strip()\n",
    "        if modismo:\n",
    "            modismos_unicos.add(modismo.casefold())\n",
    "\n",
    "n_modismos_unicos = len(modismos_unicos)\n",
    "n_models = len(models_data['text_models'])\n",
    "\n",
    "print(f\"Total unique modismos: {n_modismos_unicos:,}\")\n",
    "print(f\"Total models available: {n_models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4207844",
   "metadata": {},
   "source": [
    "## Prompt Specifications\n",
    "\n",
    "Definition of input and output word counts for each prompt type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac2ffdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt Specifications:\n",
      "  Prompt                              Description  Input (words)  Output (words)  Total words API Calls\n",
      "Prompt 1                     Modismo → Definición            138              22          160     6,531\n",
      "Prompt 2             Modismo → Es Modismo (Sí/No)            113              21          134     6,531\n",
      "Prompt 3 Modismo + Ejemplo → Literal + Definición            227              52          279     6,531\n"
     ]
    }
   ],
   "source": [
    "# Prompt specifications (words)\n",
    "PROMPTS = {\n",
    "    'Prompt 1': {\n",
    "        'description': 'Modismo → Definición',\n",
    "        'input_words': 138,\n",
    "        'output_words': 22,\n",
    "        'n_calls': n_modismos_unicos  # One call per unique modismo\n",
    "    },\n",
    "    'Prompt 2': {\n",
    "        'description': 'Modismo → Es Modismo (Sí/No)',\n",
    "        'input_words': 113,\n",
    "        'output_words': 21,\n",
    "        'n_calls': n_modismos_unicos  # One call per unique modismo\n",
    "    },\n",
    "    'Prompt 3': {\n",
    "        'description': 'Modismo + Ejemplo → Literal + Definición',\n",
    "        'input_words': 227,\n",
    "        'output_words': 52,\n",
    "        'n_calls': n_modismos_unicos  # One call per unique modismo\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display prompt specifications\n",
    "prompt_df = pd.DataFrame([\n",
    "    {\n",
    "        'Prompt': name,\n",
    "        'Description': info['description'],\n",
    "        'Input (words)': info['input_words'],\n",
    "        'Output (words)': info['output_words'],\n",
    "        'Total words': info['input_words'] + info['output_words'],\n",
    "        'API Calls': f\"{info['n_calls']:,}\"\n",
    "    }\n",
    "    for name, info in PROMPTS.items()\n",
    "])\n",
    "\n",
    "print(\"\\nPrompt Specifications:\")\n",
    "print(prompt_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de9affd",
   "metadata": {},
   "source": [
    "## Cost Calculation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a6173c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(model, input_words, output_words):\n",
    "    \"\"\"\n",
    "    Calculate the cost in coins for a single API call.\n",
    "    \n",
    "    Args:\n",
    "        model: Model pricing information dictionary\n",
    "        input_words: Number of input words\n",
    "        output_words: Number of output words\n",
    "    \n",
    "    Returns:\n",
    "        Total cost in coins for the call\n",
    "    \"\"\"\n",
    "    pricing = model['pricing']\n",
    "    coins_per_100_words = pricing['coins']\n",
    "    \n",
    "    total_words = input_words + output_words\n",
    "    cost = (total_words / 100.0) * coins_per_100_words\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c1e5b",
   "metadata": {},
   "source": [
    "## Total Cost Calculation per Model and Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86c7707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Analysis Summary:\n",
      "================================================================================\n",
      "                                                Model                                   Model ID  Coins/100 words  Prompt 1 (total)  Prompt 2 (total)  Prompt 3 (total)   Total Cost\n",
      "                               Amazon: Nova Micro 1.0                       amazon/nova-micro-v1             0.10          1,044.96            875.15          1,822.15     3,742.26\n",
      "                                     Microsoft: Phi 4                            microsoft/phi-4             0.10          1,044.96            875.15          1,822.15     3,742.26\n",
      "                                Amazon: Nova Lite 1.0                        amazon/nova-lite-v1             0.20          2,089.92          1,750.31          3,644.30     7,484.53\n",
      "                          Cohere: Command R (08-2024)                   cohere/command-r-08-2024             0.20          2,089.92          1,750.31          3,644.30     7,484.53\n",
      "                           Google: Gemini Flash 2.08B                google/gemini-2.0-flash-001             0.20          2,089.92          1,750.31          3,644.30     7,484.53\n",
      "                             Mistral: Codestral Mamba                  mistralai/codestral-mamba             0.20          2,089.92          1,750.31          3,644.30     7,484.53\n",
      "                                Qwen2-VL 72B Instruct                qwen/qwen-2-vl-72b-instruct             0.20          2,089.92          1,750.31          3,644.30     7,484.53\n",
      "                                 Qwen2.5 72B Instruct                 qwen/qwen-2.5-72b-instruct             0.20          2,089.92          1,750.31          3,644.30     7,484.53\n",
      "                                  Google: Gemma 2 27B                      google/gemma-2-27b-it             0.40          4,179.84          3,500.62          7,288.60    14,969.05\n",
      "                                  Qwen 2 72B Instruct                   qwen/qwen-2-72b-instruct             0.50          5,224.80          4,375.77          9,110.75    18,711.32\n",
      "                                   OpenAI: GPT-5 Nano                          openai/gpt-5-nano             0.50          5,224.80          4,375.77          9,110.75    18,711.32\n",
      "              NVIDIA: Llama 3.3 Nemotron Super 49B v1     nvidia/llama-3.3-nemotron-super-49b-v1             0.50          5,224.80          4,375.77          9,110.75    18,711.32\n",
      "                                 OpenAI: GPT-4.1 Nano                        openai/gpt-4.1-nano             0.50          5,224.80          4,375.77          9,110.75    18,711.32\n",
      "                                  MiniMax: MiniMax M2                    minimax/minimax-m2:free             0.50          5,224.80          4,375.77          9,110.75    18,711.32\n",
      "                         Meta: Llama 3.3 70B Instruct          meta-llama/llama-3.3-70b-instruct             0.50          5,224.80          4,375.77          9,110.75    18,711.32\n",
      "                        Google: Gemini 2.5 Flash Lite               google/gemini-2.5-flash-lite             0.50          5,224.80          4,375.77          9,110.75    18,711.32\n",
      "NVIDIA: Llama 3.3 Nemotron Super 49B V1.5 (Reasoning)   nvidia/llama-3.3-nemotron-super-49b-v1.5             0.50          5,224.80          4,375.77          9,110.75    18,711.32\n",
      "                      Qwen: Qwen3 235B A22B Reasoning                       qwen/qwen3-235b-a22b             0.60          6,269.76          5,250.92         10,932.89    22,453.58\n",
      "                                     WizardLM-2 8x22B                 microsoft/wizardlm-2-8x22b             0.60          6,269.76          5,250.92         10,932.89    22,453.58\n",
      "                         Meta: Llama 3.1 70B Instruct          meta-llama/llama-3.1-70b-instruct             0.70          7,314.72          6,126.08         12,755.04    26,195.84\n",
      "                               Meta: Llama 4 Maverick                meta-llama/llama-4-maverick             0.70          7,314.72          6,126.08         12,755.04    26,195.84\n",
      "             NVIDIA: Llama 3.1 Nemotron Ultra 253B v1    nvidia/llama-3.1-nemotron-ultra-253b-v1             0.70          7,314.72          6,126.08         12,755.04    26,195.84\n",
      "                        Qwen: Qwen2.5 VL 32B Instruct          qwen/qwen2.5-vl-32b-instruct:free             0.70          7,314.72          6,126.08         12,755.04    26,195.84\n",
      "                                 OpenAI: GPT-4.1 Mini                        openai/gpt-4.1-mini             1.00         10,449.60          8,751.54         18,221.49    37,422.63\n",
      "                                     xAI: Grok 4 Fast                           x-ai/grok-4-fast             1.00         10,449.60          8,751.54         18,221.49    37,422.63\n",
      "                                        Z.AI: GLM 4.6                               z-ai/glm-4.6             1.00         10,449.60          8,751.54         18,221.49    37,422.63\n",
      "                             Z.AI: GLM 4.5V Reasoning                              z-ai/glm-4.5v             1.00         10,449.60          8,751.54         18,221.49    37,422.63\n",
      "                                   OpenAI: GPT-5 Mini                          openai/gpt-5-mini             1.00         10,449.60          8,751.54         18,221.49    37,422.63\n",
      "                             MoonshotAI: Kimi K2 0711                    moonshotai/kimi-k2:free             1.00         10,449.60          8,751.54         18,221.49    37,422.63\n",
      "                                    Perplexity: Sonar                           perplexity/sonar             1.00         10,449.60          8,751.54         18,221.49    37,422.63\n",
      "                            Mistral: Mistral Medium 3                 mistralai/mistral-medium-3             1.00         10,449.60          8,751.54         18,221.49    37,422.63\n",
      "                   Meta: Llama 3 70B Instruct (nitro)      meta-llama/llama-3-70b-instruct:nitro             1.00         10,449.60          8,751.54         18,221.49    37,422.63\n",
      "                           Gryphe: MythoMax L2 13B 8k                     gryphe/mythomax-l2-13b             1.00         10,449.60          8,751.54         18,221.49    37,422.63\n",
      "                                Mistral: Mixtral 8x7B            mistralai/mixtral-8x7b-instruct             1.00         10,449.60          8,751.54         18,221.49    37,422.63\n",
      "                             Google: Gemini 2.5 Flash                    google/gemini-2.5-flash             1.00         10,449.60          8,751.54         18,221.49    37,422.63\n",
      "                             Dolphin 2.6 Mixtral 8x7B cognitivecomputations/dolphin-mixtral-8x7b             1.00         10,449.60          8,751.54         18,221.49    37,422.63\n",
      "                           DeepSeek: DeepSeek V3 0324             deepseek/deepseek-chat-v3-0324             1.00         10,449.60          8,751.54         18,221.49    37,422.63\n",
      "                                          DeepSeek V3                     deepseek/deepseek-chat             1.10         11,494.56          9,626.69         20,043.64    41,164.89\n",
      "                      xAI: Grok 3 Mini Beta Reasoning                      x-ai/grok-3-mini-beta             1.30         13,584.48         11,377.00         23,687.94    48,649.42\n",
      "                             OpenAI: o3 Mini (Medium)                             openai/o3-mini             1.50         15,674.40         13,127.31         27,332.24    56,133.95\n",
      "                                      OpenAI: o4 Mini                             openai/o4-mini             1.50         15,674.40         13,127.31         27,332.24    56,133.95\n",
      "                        Meta: Llama 3.1 405B Instruct         meta-llama/llama-3.1-405b-instruct             1.60         16,719.36         14,002.46         29,154.38    59,876.21\n",
      "                              DeepSeek: DeepSeek V3.1                deepseek/deepseek-chat-v3.1             2.00         20,899.20         17,503.08         36,442.98    74,845.26\n",
      "                             MoonshotAI: Kimi K2 0905                    moonshotai/kimi-k2-0905             2.00         20,899.20         17,503.08         36,442.98    74,845.26\n",
      "                          Perplexity: Sonar Reasoning                 perplexity/sonar-reasoning             2.20         22,989.12         19,253.39         40,087.28    82,329.79\n",
      "                                 OpenAI: o4 Mini High                        openai/o4-mini-high             2.40         25,079.04         21,003.70         43,731.58    89,814.31\n",
      "                               OpenAI: o3 Mini (High)                        openai/o3-mini-high             3.00         31,348.80         26,254.62         54,664.47   112,267.89\n",
      "                                    Qwen: Qwen3 Coder                           qwen/qwen3-coder             3.00         31,348.80         26,254.62         54,664.47   112,267.89\n",
      "                                      OpenAI: GPT-4.1                             openai/gpt-4.1             3.00         31,348.80         26,254.62         54,664.47   112,267.89\n",
      "                                     xAI: Grok 2 1212                           x-ai/grok-2-1212             3.20         33,438.72         28,004.93         58,308.77   119,752.42\n",
      "                         Cohere: Command R+ (08-2024)              cohere/command-r-plus-08-2024             3.40         35,528.64         29,755.24         61,953.07   127,236.94\n",
      "                               Google: Gemini Pro 1.5                      google/gemini-pro-1.5             3.70         38,663.52         32,380.70         67,419.51   138,463.73\n",
      "                                      OpenAI: o1 mini                             openai/o1-mini             4.00         41,798.40         35,006.16         72,885.96   149,690.52\n",
      "                                         Goliath 120B                     alpindale/goliath-120b             5.00         52,248.00         43,757.70         91,107.45   187,113.15\n",
      "                                   OpenAI: GPT-5 Chat                          openai/gpt-5-chat             5.00         52,248.00         43,757.70         91,107.45   187,113.15\n",
      "              DeepSeek: DeepSeek R1 Reasoning (nitro)                 deepseek/deepseek-r1:nitro             5.16         53,919.94         45,157.95         94,022.89   193,100.77\n",
      "                      DeepSeek: DeepSeek R1 Reasoning                       deepseek/deepseek-r1             5.16         53,919.94         45,157.95         94,022.89   193,100.77\n",
      "                           Anthropic: Claude Sonnet 4                  anthropic/claude-sonnet-4             6.00         62,697.60         52,509.24        109,328.94   224,535.78\n",
      "                                        OpenAI: GPT-5                               openai/gpt-5             8.00         83,596.80         70,012.32        145,771.92   299,381.04\n",
      "                                     xAI: Grok 3 Beta                           x-ai/grok-3-beta             8.00         83,596.80         70,012.32        145,771.92   299,381.04\n",
      "                         Anthropic: Claude Sonnet 4.5                anthropic/claude-sonnet-4.5            10.00        104,496.00         87,515.40        182,214.90   374,226.30\n",
      "                                xAI: Grok 4 Reasoning                                x-ai/grok-4            10.00        104,496.00         87,515.40        182,214.90   374,226.30\n",
      "           Google: Gemini Pro 2.5 Reasoning (Preview)              google/gemini-2.5-pro-preview            16.60        173,463.36        145,275.56        302,476.73   621,215.66\n",
      "                                           OpenAI: o1                                  openai/o1            20.00        208,992.00        175,030.80        364,429.80   748,452.60\n",
      "                                           OpenAI: o3                              o3-2025-04-16            20.00        208,992.00        175,030.80        364,429.80   748,452.60\n",
      "                           Anthropic: Claude Opus 4.1                    anthropic/claude-opus-4            30.00        313,488.00        262,546.20        546,644.70 1,122,678.90\n",
      "                            OpenAI: o1 High Reasoning                              openai/o1-pro            35.00        365,736.00        306,303.90        637,752.15 1,309,792.05\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Calculate costs for all models and prompts\n",
    "cost_analysis = []\n",
    "\n",
    "for model in models_data['text_models']:\n",
    "    model_name = model['name']\n",
    "    model_id = model['model']\n",
    "    pricing_info = model['pricing']\n",
    "    \n",
    "    model_costs = {\n",
    "        'Model': model_name,\n",
    "        'Model ID': model_id,\n",
    "        'Coins/100 words': pricing_info['coins']\n",
    "    }\n",
    "    \n",
    "    total_model_cost = 0\n",
    "    \n",
    "    for prompt_name, prompt_info in PROMPTS.items():\n",
    "        cost_per_call = calculate_cost(\n",
    "            model,\n",
    "            prompt_info['input_words'],\n",
    "            prompt_info['output_words']\n",
    "        )\n",
    "        \n",
    "        total_prompt_cost = cost_per_call * prompt_info['n_calls']\n",
    "        model_costs[f\"{prompt_name} (total)\"] = total_prompt_cost\n",
    "        total_model_cost += total_prompt_cost\n",
    "    \n",
    "    model_costs['Total Cost'] = total_model_cost\n",
    "    cost_analysis.append(model_costs)\n",
    "\n",
    "# Create DataFrame\n",
    "cost_df = pd.DataFrame(cost_analysis)\n",
    "\n",
    "# Sort by total cost\n",
    "cost_df = cost_df.sort_values('Total Cost', ascending=True)\n",
    "\n",
    "print(\"Cost Analysis Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(cost_df.to_string(index=False, float_format=\"{:,.2f}\".format))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "cost_df.to_excel('Straico_Cost_Analysis.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ba6b813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grand Total Cost:\n",
      "9,229,169.01 coins\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the total cost across all models and prompts\n",
    "total_cost = cost_df['Total Cost'].sum()\n",
    "print(\"\\nGrand Total Cost:\")\n",
    "print(f\"{total_cost:,.2f} coins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa55103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "926d5b74",
   "metadata": {},
   "source": [
    "## Dataset Filtering: Remove Duplicates and Empty Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf3633bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: 10,195 rows\n",
      "\n",
      "Columns: ['modismo', 'significado', 'ejemplo', 'fuente']\n",
      "\n",
      "First few rows:\n",
      "    modismo                                        significado  \\\n",
      "0   abajeño  Propio o nativo de las costas o de las tierras...   \n",
      "1   abalear  Disparar a alguien o a algo de manera repetida...   \n",
      "2   abalear  Herir o matar a alguien con disparos de un arm...   \n",
      "3    abaleo  Situación en la que hay disparos repetidos que...   \n",
      "4  abanicar  En el beisbol, fallar el bateador al no tocar ...   \n",
      "\n",
      "                                             ejemplo fuente  \n",
      "0  Empezaron cultivos de tabaco y a elaborar un d...  DICOL  \n",
      "1  El funcionario resultó ileso a pesar de que el...  DICOL  \n",
      "2  Limpiaba la hojarasca cuando hombres armados l...  DICOL  \n",
      "3  Por la calle doce se oía un tremendo abaleo y ...  DICOL  \n",
      "4  El bateador se ponchó abanicando el tercer lan...  DICOL  \n"
     ]
    }
   ],
   "source": [
    "# Load the original dataset\n",
    "df = pd.read_csv(DATASET_FILE, delimiter=';', encoding='utf-8')\n",
    "\n",
    "print(f\"Original dataset: {len(df):,} rows\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "311503cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After removing duplicates: 6,531 rows\n",
      "Duplicates removed: 3,664 rows\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Remove duplicates based on 'modismo' column (case-insensitive)\n",
    "# Create a temporary column for case-insensitive comparison\n",
    "df['modismo_lower'] = df['modismo'].str.strip().str.lower()\n",
    "\n",
    "# Remove duplicates keeping the first occurrence\n",
    "df_no_duplicates = df.drop_duplicates(subset='modismo_lower', keep='first')\n",
    "\n",
    "# Drop the temporary column\n",
    "df_no_duplicates = df_no_duplicates.drop(columns=['modismo_lower'])\n",
    "\n",
    "print(f\"\\nAfter removing duplicates: {len(df_no_duplicates):,} rows\")\n",
    "print(f\"Duplicates removed: {len(df) - len(df_no_duplicates):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0f264a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After removing empty ejemplo: 4,616 rows\n",
      "Empty ejemplo removed: 1,915 rows\n",
      "\n",
      "Total rows removed: 5,579\n",
      "Final dataset: 4,616 rows (45.3% of original)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Remove rows without definition (ejemplo)\n",
    "# Check for empty, null, or whitespace-only definitions\n",
    "df_filtered = df_no_duplicates[\n",
    "    df_no_duplicates['ejemplo'].notna() & \n",
    "    (df_no_duplicates['ejemplo'].str.strip() != '')\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nAfter removing empty ejemplo: {len(df_filtered):,} rows\")\n",
    "print(f\"Empty ejemplo removed: {len(df_no_duplicates) - len(df_filtered):,} rows\")\n",
    "print(f\"\\nTotal rows removed: {len(df) - len(df_filtered):,}\")\n",
    "print(f\"Final dataset: {len(df_filtered):,} rows ({len(df_filtered)/len(df)*100:.1f}% of original)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "081feb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv('modismos_Dataset_Cleaned.csv', index=False, sep=';', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
